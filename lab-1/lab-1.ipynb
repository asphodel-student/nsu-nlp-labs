{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Task 1\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "Lz7LjpPkLB_b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hPrb55_50RFF",
    "ExecuteTime": {
     "end_time": "2023-09-28T16:02:13.034193368Z",
     "start_time": "2023-09-28T16:02:10.508217226Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the dataset"
   ],
   "metadata": {
    "id": "ZkG-zb4HLJqD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df = train_df.drop('idx', axis=1)\n",
    "train_df = train_df[['Text', 'Score']]\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_df = test_df.drop('idx', axis=1)"
   ],
   "metadata": {
    "id": "-sp_4rs-3abK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the model"
   ],
   "metadata": {
    "id": "6qAsbNs2LMHj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m spacy download ru_core_news_sm\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNlulnokEXyC",
    "outputId": "dea7d688-e5a1-408c-ec3b-f245db7e2a6a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split dataset and create .spacy files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = [tuple(train_df.iloc[i].values) for i in range(train_df.shape[0])]\n",
    "test = [tuple(test_df.iloc[i].values) for i in range(test_df.shape[0])]\n",
    "\n",
    "dividing_point = int(len(data) * 0.75)\n",
    "\n",
    "train_data = data[:dividing_point]\n",
    "test_data = data[dividing_point:]"
   ],
   "metadata": {
    "id": "zKG7hpNRE5jC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_docs(data):\n",
    "    \"\"\"\n",
    "    this will take a list of texts and labels\n",
    "    and transform them in spacy documents\n",
    "    data: list(tuple(text, label))\n",
    "    returns: List(spacy.Doc.doc)\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    # nlp.pipe([texts]) is way faster than running\n",
    "    # nlp(text) for each text\n",
    "    # as_tuples allows us to pass in a tuple,\n",
    "    # the first one is treated as text\n",
    "    # the second one will get returned as it is.\n",
    "    # a = tqdm(nlp.pipe(data, as_tuples=True), total = len(data))\n",
    "    for doc, label in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        doc.cats[\"Positive\"] = int(label == 'Positive')\n",
    "        doc.cats[\"Negative\"] = int(label == 'Negative')\n",
    "        \n",
    "        # we need to set the (text)cat(egory) for each document\n",
    "        #doc.cats[\"positive\"] = label\n",
    "        # put them into a nice list\n",
    "        docs.append(doc)\n",
    "    return docs"
   ],
   "metadata": {
    "id": "Ni2OdmMDFPfw",
    "ExecuteTime": {
     "end_time": "2023-09-28T16:10:58.673026288Z",
     "start_time": "2023-09-28T16:10:58.663305725Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_docs = make_docs(train_data)\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"train.spacy\") \n",
    "\n",
    "valid_docs = make_docs(test_data)\n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"valid.spacy\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJXccgX7FRpv",
    "outputId": "2eb94a50-1da9-4ea8-ecea-64f44019933b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make a config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ],
   "metadata": {
    "id": "SL0G1W57ILBp",
    "ExecuteTime": {
     "end_time": "2023-09-28T15:39:53.195759951Z",
     "start_time": "2023-09-28T15:39:51.377563757Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Auto-filled config with all values\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Saved config\u001B[0m\r\n",
      "config.cfg\r\n",
      "You can now add your data and train your pipeline:\r\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train our model :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./valid.spacy --gpu-id 0"
   ],
   "metadata": {
    "id": "spgJ-OG7IPUK",
    "ExecuteTime": {
     "end_time": "2023-09-28T16:32:56.225408470Z",
     "start_time": "2023-09-28T16:17:35.368636106Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Saving to output directory: output\u001B[0m\r\n",
      "\u001B[38;5;4mℹ Using GPU: 0\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "=========================== Initializing pipeline ===========================\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Initialized pipeline\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "============================= Training pipeline =============================\u001B[0m\r\n",
      "\u001B[38;5;4mℹ Pipeline: ['tok2vec', 'textcat']\u001B[0m\r\n",
      "\u001B[38;5;4mℹ Initial learn rate: 0.0001\u001B[0m\r\n",
      "E    #       LOSS TOK2VEC  LOSS TEXTCAT  CATS_SCORE  SCORE \r\n",
      "---  ------  ------------  ------------  ----------  ------\r\n",
      "  0       0          0.00          0.25       33.85    0.34\r\n",
      "  0     200          0.29         52.30       34.40    0.34\r\n",
      "  0     400          0.67         52.35       47.91    0.48\r\n",
      "  0     600          1.35         54.76       42.08    0.42\r\n",
      "  0     800          3.01         53.81       59.53    0.60\r\n",
      "  0    1000         11.32         55.71       55.43    0.55\r\n",
      "  0    1200         10.46         59.86       60.23    0.60\r\n",
      "  0    1400         22.63         63.18       54.90    0.55\r\n",
      "  0    1600         22.51         59.02       56.58    0.57\r\n",
      "  0    1800         22.49         56.78       68.90    0.69\r\n",
      "  0    2000         54.02         50.72       69.77    0.70\r\n",
      "  0    2200         41.49         51.47       66.75    0.67\r\n",
      "  0    2400         34.68         54.30       67.58    0.68\r\n",
      "  0    2600         29.23         47.79       70.75    0.71\r\n",
      "  0    2800         47.79         43.00       71.90    0.72\r\n",
      "  0    3000         81.19         43.11       69.75    0.70\r\n",
      "  0    3200        101.44         43.16       73.14    0.73\r\n",
      "  0    3400         97.40         40.18       70.76    0.71\r\n",
      "  0    3600         92.11         44.90       72.56    0.73\r\n",
      "  0    3800        109.36         48.00       73.97    0.74\r\n",
      "  0    4000         72.16         42.69       74.08    0.74\r\n",
      "  0    4200         82.11         42.27       72.44    0.72\r\n",
      "  0    4400         68.78         43.65       75.94    0.76\r\n",
      "  0    4600         68.41         37.67       74.68    0.75\r\n",
      "  0    4800        103.61         36.60       78.13    0.78\r\n",
      "  0    5000         75.87         34.40       80.34    0.80\r\n",
      "  0    5200        134.68         37.08       78.78    0.79\r\n",
      "  0    5400        110.37         36.90       80.66    0.81\r\n",
      "  0    5600         73.74         34.91       81.02    0.81\r\n",
      "  0    5800         65.10         31.63       82.26    0.82\r\n",
      "  1    6000         86.33         32.12       81.33    0.81\r\n",
      "  1    6200         75.11         33.16       80.48    0.80\r\n",
      "  1    6400         64.02         32.47       79.56    0.80\r\n",
      "  1    6600         62.58         23.15       82.17    0.82\r\n",
      "  1    6800         85.61         32.44       79.24    0.79\r\n",
      "  1    7000         71.23         29.48       81.55    0.82\r\n",
      "  1    7200         68.51         32.69       77.99    0.78\r\n",
      "  1    7400        126.78         28.55       81.53    0.82\r\n",
      "\u001B[38;5;2m✔ Saved pipeline to output directory\u001B[0m\r\n",
      "output/model-last\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current position: 0 / 3500\n",
      "Current position: 100 / 3500\n",
      "Current position: 200 / 3500\n",
      "Current position: 300 / 3500\n",
      "Current position: 400 / 3500\n",
      "Current position: 500 / 3500\n",
      "Current position: 600 / 3500\n",
      "Current position: 700 / 3500\n",
      "Current position: 800 / 3500\n",
      "Current position: 900 / 3500\n",
      "Current position: 1000 / 3500\n",
      "Current position: 1100 / 3500\n",
      "Current position: 1200 / 3500\n",
      "Current position: 1300 / 3500\n",
      "Current position: 1400 / 3500\n",
      "Current position: 1500 / 3500\n",
      "Current position: 1600 / 3500\n",
      "Current position: 1700 / 3500\n",
      "Current position: 1800 / 3500\n",
      "Current position: 1900 / 3500\n",
      "Current position: 2000 / 3500\n",
      "Current position: 2100 / 3500\n",
      "Current position: 2200 / 3500\n",
      "Current position: 2300 / 3500\n",
      "Current position: 2400 / 3500\n",
      "Current position: 2500 / 3500\n",
      "Current position: 2600 / 3500\n",
      "Current position: 2700 / 3500\n",
      "Current position: 2800 / 3500\n",
      "Current position: 2900 / 3500\n",
      "Current position: 3000 / 3500\n",
      "Current position: 3100 / 3500\n",
      "Current position: 3200 / 3500\n",
      "Current position: 3300 / 3500\n",
      "Current position: 3400 / 3500\n",
      "0.8231428571428572\n"
     ]
    }
   ],
   "source": [
    "# # load the best model from training\n",
    "# nlp = spacy.load(\"output/model-best\")\n",
    "# \n",
    "# correct_answers = 0\n",
    "# all_answers = len(test_data)\n",
    "# \n",
    "# for i, string in enumerate(test_data):\n",
    "#     \n",
    "#     if i % 100 == 0:\n",
    "#         print('Current position: {} / {}'.format(i, all_answers))\n",
    "# \n",
    "#     output = nlp(string[0])\n",
    "# \n",
    "#     if (output.cats['Positive'] > 0.5 and string[1] == 'Positive') or (output.cats['Negative'] > 0.5 and string[1] == 'Negative'):\n",
    "#         correct_answers += 1\n",
    "#         \n",
    "# print(correct_answers / all_answers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T16:40:08.096386139Z",
     "start_time": "2023-09-28T16:37:41.822196193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "print(\"type : ‘quit’ to exit\")\n",
    "# predict the sentiment until someone writes quit\n",
    "while text != \"quit\":\n",
    "    text = input(\"Please enter example input: \")\n",
    "    doc = nlp(text)\n",
    "    print(doc.cats)\n",
    "    if doc.cats['Positive'] >.5:\n",
    "        print(f\"the sentiment is positive\")\n",
    "    else:\n",
    "        print(f\"the sentiment is negative\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
